{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting accurate monthly series for campaign finance\n",
    "\n",
    "### What's the issue? Why is this so hard?\n",
    "The problem in trying to show accurate monthly campaign finance total fundraising, of the sort used in visualizations like the NYT's [2012 Money Race](http://elections.nytimes.com/2012/campaign-finance) is the simple one that campaigns do not actually report data monthly. This was the [presidential principal campaign committee reporting schedule](http://www.fec.gov/info/report_dates_2012.shtml#monthly) for the 2012 election. You can see that campaigns reported quarterly in 2011, and only began monthly reports in 2012. In addition, because the election is in November, reporting deadlines mean that the final three periods are not quite monthly and all have highly skewed coverage periods which need to be adjusted for as well.\n",
    "\n",
    "### But the FEC has all this itemized data available with transaction dates - why can't we use that?\n",
    "The itemized data is only a small subset of the overal data. So in the 2012 election cycle, for instance, Obama for America raised 738.5 million, of which 315 million came from individal donors that gave more than 200 bucks, and 234 million came from individual donors that gave less than 200 bucks (the rest came from authorized committees and a few other places). But donations less than 200 aren't required to be itemized, so they don't show up in the itemized dataset. In addition, the 315 million number includes donations from those who gave over 200 in total, but in a series of smaller donations. These also don't show up in the FEC's itemized data, so the itemized data only include about 200 mm - a small fraction of the total. If we looked at these, we would think that Romney had massively outraised Obama - but in fact the opposite was true.\n",
    "\n",
    "### So what do we do?\n",
    "\n",
    "The FEC Form 3P data represents the accurate totals, but is a mixture of quarterly and monthly data. The itemized data is only a fraction of the total, but we have dates for every single itemized contribution. So we can use the itemized data as a proxy for the overal time distribution of fundraising, and use the amount that each month represents out of the quarterly totals to prorate the Form 3P data where that data is quarterly.\n",
    "\n",
    "### What data sources do we use\n",
    "Getting the Form 3P data is harder than it would seem - the FEC website lets you download spreadsheets with totals, but it's a highly manual process - no persistent links. Better is to use the new beta FEC API, which makes it very easy to get the Form 3P data.\n",
    "\n",
    "For the itemized data, the API isn't suitable - while the itemized data is available, the endpoints that give aggregates don't give us enough detail or control, while the endpoints that give true itemized data don't at the moment let you filter or agregate to get to a point where the data size is limited - and so as a result there are huge rate limiting problems going down this route. Much better to use the csv files the FEC makes available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests, json, zipfile, StringIO, urllib2, os, re\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import dateutil.parser\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up to get Form 3P data through the FEC Beta API\n",
    "While there is a [python wrapper](https://github.com/jeremyjbowers/pyopenfec) available, it isn't well maintained, and breaking changes to the API have already caused problems. Since what we want is super simple to get, much better to just use requests and hit the REST API endpoints directly. The functions below are set up to do that.\n",
    "\n",
    "Anyone who wants to get an excel spreadsheet to look at for comparison can go to http://www.fec.gov/data/CommitteeSummary.do?format=html&election_yr=2012 and enter in a campaign code and click through and eventually get one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_URL = 'https://api.open.fec.gov/v1'\n",
    "envVars = %env\n",
    "API_KEY = envVars['OPENFEC_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_results(endpoint, params):\n",
    "    params['api_key'] = API_KEY\n",
    "    url = BASE_URL+endpoint\n",
    "    r = requests.get(url, params=params)\n",
    "    initial_data = r.json()\n",
    "    num_pages = initial_data['pagination']['pages']\n",
    "    num_records = initial_data['pagination']['count']\n",
    "    current_page = initial_data['pagination']['page']\n",
    "    for record in initial_data['results']:\n",
    "        yield record\n",
    "\n",
    "    while current_page < num_pages:\n",
    "        current_page += 1\n",
    "        params['page']=current_page\n",
    "        data = requests.get(url, params=params).json()\n",
    "        for record in data['results']:\n",
    "            yield record\n",
    "\n",
    "def count_results(endpoint, params):\n",
    "    params['api_key'] = API_KEY\n",
    "    url = BASE_URL+endpoint\n",
    "    data = requests.get(url, params=params).json()\n",
    "    return data['pagination']['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../App/data/candidates.json', 'r') as f:\n",
    "    candidate_data = json.load(f)\n",
    "candidate_data = { year: candidate_data[year] for year in candidate_data.keys() if int(year) >= 2008 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "form3 = {}\n",
    "\n",
    "def form3totals(committee_id, cycle):\n",
    "    \n",
    "    key = (committee_id, cycle)\n",
    "    \n",
    "    if key not in form3:\n",
    "        q = {\n",
    "            'cycle':cycle,\n",
    "            'per_page':100,\n",
    "            'is_amended':False,\n",
    "        }\n",
    "        data = []\n",
    "        for r in all_results('/committee/'+committee_id+'/reports/', q):\n",
    "            data.append({\n",
    "                    'Report Year': r[\"report_year\"],\n",
    "                    'Report Type': r[\"report_type\"],\n",
    "                    'Report Period': str(r[\"report_year\"])+'-'+r[\"report_type\"],\n",
    "                    'Coverage Start Date': dateutil.parser.parse(r[\"coverage_start_date\"]).date(),\n",
    "                    'Coverage End Date': dateutil.parser.parse(r[\"coverage_end_date\"]).date(),\n",
    "                    'Total Receipts': r[\"total_receipts_period\"],\n",
    "                    'Total Disbursements': r[\"total_disbursements_period\"],\n",
    "                })\n",
    "        columns = [\n",
    "            'Report Period',\n",
    "            'Coverage Start Date',\n",
    "            'Coverage End Date',\n",
    "            'Total Receipts',\n",
    "            'Total Disbursements',\n",
    "        ]\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "\n",
    "        df.set_index('Report Period', inplace=True)\n",
    "        df.sort_values(by='Coverage Start Date')\n",
    "        df.name = \"%s-%d\" % (committee_id, int(cycle))\n",
    "        form3[key] = df\n",
    "    \n",
    "    cached = form3[key]\n",
    "    return form3[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the itemized data in bulk in csv form from the FEC website\n",
    "The below gets all of the available itemized data from the FEC - just uncomment the function call to run for a specified year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To download all schedule detail csv files for a particular year\n",
    "\n",
    "schedule_dict = {'Committees': {'abbrev':'cm', 'filename':'cm'},\n",
    "            'Candidates': {'abbrev':'cn', 'filename':'cn'},\n",
    "            'Candidate Committee Linkage': {'abbrev':'ccl', 'filename':'ccl'},\n",
    "            'Committee to Committee Trans': {'abbrev':'oth', 'filename':'itoth'},\n",
    "            'Contributions by Committees': {'abbrev':'pas2', 'filename':'itpas2'},\n",
    "            'Contributions by Individuals': {'abbrev':'indiv', 'filename':'itcont'},\n",
    "            'Operating Expenditures': {'abbrev':'oppexp', 'filename':'oppexp'}\n",
    "             }\n",
    "header_url_base = 'http://www.fec.gov/finance/disclosure/metadata/%s_header_file.csv'\n",
    "data_url_base = 'ftp://ftp.fec.gov/FEC/20%02d/%s%02d.zip'\n",
    "\n",
    "\n",
    "def get_schedule_data(year, schedule_dict):\n",
    "    yearlasttwo = int(str(year)[2:])\n",
    "    for f in schedule_dict.values():\n",
    "        pathname = '%s_%s.csv' % (year, f['abbrev'])\n",
    "        if not (os.path.isfile(pathname) and os.path.getsize(pathname) > 0):\n",
    "            data_url = data_url_base % (yearlasttwo, f['abbrev'], yearlasttwo)\n",
    "            print \" downloading %s into %s...\" % (data_url, pathname),\n",
    "            r = requests.get(header_url_base % f['abbrev'])\n",
    "            f['headers'] = r.content.strip().split(',')\n",
    "            d = urllib2.urlopen(data_url)\n",
    "            z = zipfile.ZipFile(StringIO.StringIO(d.read()))\n",
    "            data = pd.read_csv(z.open('%s.txt' % f['filename']), sep='|', header=None, names=f['headers'], index_col=False,\n",
    "                        low_memory=False)\n",
    "            data.to_csv(pathname, index=True)\n",
    "            print \"done.\"\n",
    "        else:\n",
    "            print \" skipping %s.\" % pathname\n",
    "\n",
    "for cycle in sorted(candidate_data.keys()):\n",
    "    print \"downloading data for\", cycle\n",
    "    get_schedule_data(cycle, schedule_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Individual Contributions data\n",
    "This just dumps the small number of cases where we don't have any dates for contributions, and then adds month year and quarter indices to make later manipulation easy, before saving the csv file back down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Process the individual contributions and operating expenditure csv        \n",
    "def process_date(year, in_format, out_format, date_format, date_preformat=None):\n",
    "    pathname_in = in_format % year\n",
    "    pathname_out = out_format % year\n",
    "    if os.path.isfile(pathname_in) and os.path.getsize(pathname_in) > 0:\n",
    "        if not (os.path.isfile(pathname_out) and os.path.getsize(pathname_out) > 0):\n",
    "            print \" processing %s into %s...\" % (pathname_in, pathname_out),\n",
    "            df = pd.read_csv(pathname_in, low_memory=False, index_col=0)\n",
    "            df = df[df['TRANSACTION_DT'].notnull()].copy() # if there isn't a date, no use to us\n",
    "            df['DATE'] = df['TRANSACTION_DT'] if date_preformat is None else df['TRANSACTION_DT'].apply(date_preformat)\n",
    "            df['DATE'] = pd.to_datetime(df['DATE'], format=date_format, errors='coerce')\n",
    "            df = df[df['DATE'].notnull()]\n",
    "            df['MONTH'] = pd.DatetimeIndex(df['DATE']).month\n",
    "            df['QUARTER'] = pd.DatetimeIndex(df['DATE']).quarter\n",
    "            df['YEAR'] = pd.DatetimeIndex(df['DATE']).year\n",
    "            df[['MONTH', 'QUARTER', 'YEAR']] = df[['MONTH', 'QUARTER', 'YEAR']].astype(int)\n",
    "            df.to_csv(pathname_out)\n",
    "            print \"done.\"\n",
    "        else:\n",
    "            print \"skipping %s.\" % pathname_out\n",
    "    else:\n",
    "        print 'ERROR: %s not found' % pathname_in\n",
    "\n",
    "def process_indiv(year):\n",
    "    return process_date(year, '%s_indiv.csv', '%s_indiv_p1.csv', '%m%d%Y', lambda dt: \"{:0>8d}\".format(int(dt)))\n",
    "        \n",
    "def process_oppex(year):\n",
    "    return process_date(year,'%s_oppexp.csv', '%s_oppexp_p1.csv', '%m/%d/%Y')\n",
    "        \n",
    "for cycle in sorted(candidate_data):\n",
    "    process_indiv(cycle)\n",
    "    process_oppex(cycle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the individual contribution data into memory\n",
    "That makes it much faster to work with from that point on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indivs = pd.DataFrame()\n",
    "oppexps = pd.DataFrame()\n",
    "for cycle in sorted(candidate_data.keys()):\n",
    "    print \"reading processed data for\", cycle\n",
    "    indivs = indivs.append(pd.read_csv(cycle +'_indiv_p1.csv', low_memory=False, index_col=0))\n",
    "    oppexps = oppexps.append(pd.read_csv(cycle +'_oppexp_p1.csv', low_memory=False, index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q2m = lambda q: range(3*q - 2, 3*q + 1)\n",
    "sa2m = lambda h: range(1, 7) if h == 0 else range(7, 13)\n",
    "\n",
    "# for a given line item, which months should it distribute to?\n",
    "def f3_period_distribution(periods):\n",
    "    \n",
    "    # want to move forward in time\n",
    "    periods = periods[::]\n",
    "    periods.reverse()\n",
    "    \n",
    "    distribution = []\n",
    "    last_suffix = None\n",
    "    deferred = False\n",
    "    for period in periods:\n",
    "        split = period.split('-')\n",
    "        year = int(split[0])\n",
    "        suffix = split[1]\n",
    "        if suffix == 'YE':\n",
    "            if last_suffix is None:\n",
    "                deferred = True\n",
    "            elif last_suffix == 'MY':\n",
    "                distribution.append((year, sa2m(1)))\n",
    "            elif last_suffix[0] == 'Q':\n",
    "                distribution.append((year, q2m(4)))\n",
    "            elif last_suffix[0] == 'M':\n",
    "                distribution.append((year, [12]))\n",
    "            elif last_suffix == '30G':\n",
    "                distribution.append((year, q2m(4)))\n",
    "        elif suffix == '12G' or suffix == '30G':\n",
    "            distribution.append((year, q2m(4)))\n",
    "        elif suffix in ['12P', '12R', '12C', '12S', 'TER']:\n",
    "            distribution.append((year, []))\n",
    "        else:\n",
    "            if suffix == 'MY':\n",
    "                if deferred:\n",
    "                    distribution.append((year - 1, sa2m(1)))\n",
    "                distribution.append((year, sa2m(0)))\n",
    "            else:\n",
    "                value = int(suffix[1:])\n",
    "                if suffix[0] == 'M':\n",
    "                    if deferred:\n",
    "                        distribution.append((year - 1, [12]))\n",
    "                    distribution.append((year, [value - 1]))\n",
    "                elif suffix[0] == 'Q':\n",
    "                    if deferred:\n",
    "                        distribution.append((year - 1, q2m(4)))\n",
    "                    distribution.append((year, q2m(value)))\n",
    "                else:\n",
    "                    raise ValueError(\"unkown suffix in f3 timeline \" + suffix)\n",
    "            deferred = False\n",
    "        last_suffix = suffix\n",
    "        \n",
    "    # reverse to match f3\n",
    "    distribution.reverse()\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# pull all the values covering a distribution and calculate the normalized distribution based on indivs or opexps\n",
    "def f3_period_coeffs(committee_id, df, dist):\n",
    "    \n",
    "    year, months = dist\n",
    "    \n",
    "    df = df[df['CMTE_ID']==committee_id]\n",
    "    df = df[df['YEAR']==year]\n",
    "    df = df[df['MONTH'].isin(months)].copy()\n",
    "    \n",
    "    grouped = df.groupby(by=['YEAR', 'QUARTER', 'MONTH']).sum()['TRANSACTION_AMT']\n",
    "    monthly = pd.DataFrame({\n",
    "        'Monthly Contributions': grouped,\n",
    "    })\n",
    "    monthly['Pro Rating Coeffs'] = monthly['Monthly Contributions']/grouped.sum()\n",
    "    \n",
    "    value = monthly['Pro Rating Coeffs']\n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating monthly pro-rating coefficients from the individual contribution data\n",
    "The below function returns a series of coefficients, indexed by year, quarter and month, to be used in prorating quarterly data to monthly. At the moment it is set up to work with the itemized individual contribution data; we probably need to generalize it so it can also work on the spending side to work with the itemized spending data.\n",
    "\n",
    "The f3Monthly function then takes a form F3 period series, and a monthly pro-rating coefficient series as inputs, applies the pro-rating methodology, and returns a monthly series as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "coeff_cache = {}\n",
    "\n",
    "def f3_monthly(f3, data, committee_id, cycle):\n",
    "    \n",
    "    monthly_data = pd.Series(\n",
    "        index=pd.MultiIndex.from_tuples(\n",
    "            [(cycle - (1 - i/12), i/3 % 4 + 1, i % 12 + 1) for i in range(0, 24)],\n",
    "            names=['YEAR', 'QUARTER', 'MONTH'])).fillna(0.)\n",
    "    monthly_data.name = 'Monthly Data'\n",
    "        \n",
    "    f3_periods = f3.index.values.tolist()\n",
    "    f3_distributions = f3_period_distribution(f3_periods)\n",
    "    \n",
    "    for period, distribution in zip(f3_periods, f3_distributions):\n",
    "        year, months = distribution\n",
    "        if len(months) > 0: # months > 0?\n",
    "            if len(months) == 1:\n",
    "                distributed = pd.Series(\n",
    "                    index=pd.MultiIndex.from_tuples([(year, (months[0] - 1)/3 % 4 + 1, months[0])],\n",
    "                                                    names=['YEAR', 'QUARTER', 'MONTH']))\n",
    "                distributed = distributed.fillna(f3[period])\n",
    "            else:\n",
    "                key = (committee_id, cycle, f3.name, distribution[0], tuple(distribution[1]))\n",
    "                if key not in coeff_cache:\n",
    "                    coeff_cache[key] = f3_period_coeffs(committee_id, data, distribution)\n",
    "                coeffs = coeff_cache[key]\n",
    "                distributed = coeffs * f3[period]\n",
    "            monthly_data = monthly_data.add(distributed, fill_value=0.)\n",
    "    \n",
    "    return monthly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "cmte_names = {}\n",
    "in_monthly = {}\n",
    "out_monthly = {}\n",
    "\n",
    "for c in sorted(candidate_data.keys()):\n",
    "    print c\n",
    "    in_c = {}\n",
    "    in_monthly[c] = in_c\n",
    "    out_c = {}\n",
    "    out_monthly[c] = out_c\n",
    "    for p in sorted(candidate_data[c].keys()):\n",
    "        print \" \", p\n",
    "        cp_dicts = candidate_data[c][p]\n",
    "        for cp_dict in cp_dicts:\n",
    "            print \"  \", cp_dict['CAND_NAME']\n",
    "            cmtes = [cp_dict['Principal']]\n",
    "            cmtes.extend(cp_dict['Supporting'])\n",
    "            for cmte in cmtes:\n",
    "                cmte_id = cmte['id']\n",
    "                print \"   \",cmte_id\n",
    "                if cmte_id not in cmte_names:\n",
    "                    cmte_names[cmte_id] = cmte['name']\n",
    "                if cmte_id not in in_c:\n",
    "                    in_c[cmte_id] = indiv_monthly(cmte_id, c)\n",
    "                if cmte_id not in out_c:\n",
    "                    out_c[cmte_id] = oppexp_monthly(cmte_id, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ordered_set import OrderedSet\n",
    "from collections import OrderedDict\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import json\n",
    "\n",
    "cycle_cmte_ids = OrderedSet()\n",
    "\n",
    "for cycle in sorted(in_monthly):\n",
    "    for cmte_id in sorted(in_monthly[cycle]):\n",
    "        cycle_cmte_ids.add((cycle, cmte_id))\n",
    "for cycle in sorted(out_monthly):\n",
    "    for cmte_id in sorted(out_monthly[cycle]):\n",
    "        cycle_cmte_ids.add((cycle, cmte_id))\n",
    "\n",
    "collection = []\n",
    "for cycle_cmte_id in cycle_cmte_ids:\n",
    "    cycle, cmte_id = cycle_cmte_id\n",
    "    in_df = in_monthly[cycle][cmte_id]\n",
    "    out_df = out_monthly[cycle][cmte_id]\n",
    "    document = OrderedDict()\n",
    "    document['cycle'] = cycle\n",
    "    document['cmte_id'] = cmte_id\n",
    "    document['cmte_name'] = cmte_names[cmte_id]\n",
    "    base = date(int(cycle)-1, 1, 1)\n",
    "    document['date'] = [(base + relativedelta(months=x)).isoformat() for x in range(0, 24)]\n",
    "    document['receipts'] = in_df.clip_lower(0).values.astype(int).tolist()\n",
    "    document['expenditures'] = out_df.clip_lower(0).values.astype(int).tolist()\n",
    "    collection.append(document)\n",
    "    print document['cycle'], document['cmte_id'], document['cmte_name']\n",
    "    \n",
    "with open('cmte_finances.json', 'w') as outfile:\n",
    "    json.dump(collection, outfile)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
